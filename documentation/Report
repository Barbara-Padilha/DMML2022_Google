For this final project of the Data Mining and Machine Learning course of the autumn semester of 2022/2023, our goal was to use the knowledge obtained in class and through reasearch to analyse and classify sentences in French according to their difficulty. With this, it is possible to help non-ntive speakers to predict the difficulty of a text in French and find exemples of reading material that are appropriate depending on a persons level of understanding (`A1` to `C2`).

In order to do so, we begin by downlading all the necessary data and material to build and train our models. The data used was found on the Kaggle Competition page, and is separated in `training_data.csv`, `unlabelled_test_data.csv` and  `sample_submission.csv`. These files contain the training set, in which we will build and train our models after a split between test and train data, the actual test data that we wish to classify after our models are complete and an exemple of how our results on the test data must be submitted to Kaggle, respectively.

With all the data needed, the first step we took was to download the basic packs needed for our analysis during the project, those being:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline
sns.set_style("whitegrid")

With packages installed, we move on to check the value of our baseline in the `training_data.csv` in order to have a better understanding of our data. For this, we begin by splitting our datas into ``x_train`, `x_test`, `y_train` and `y_test`, once that was done we used two different methods to calculate the baseline. 

One of those methods was using the .value_counts() command to know values of each difficulty in the training set created and which had a bigger frequency, once we knew that, we divided the value of the most frequent difficulty by the total amount and obtained a value of 0.1694 for our baseline.

we begin our coding by downloading the necessary packages and language sets to use various classification methods and the text analysis. 

The models used to start our classification during this project were Logistic Regression, K-Nearest Neighbors, Decision Tree and Random Forest, when it comes for the text analysis, we did not use any sort of data cleaning or tokenization for the models created, we simply used the TF-IDF Vectorizer. After doing this base work to have a better understanding of our data, we chose to use Neural Networks as our extra technique for classification and with it we also applied various techniques of text analysis in order to try to improve our results.

Using the exemple of our Logistic Regression Classifier, the packages downloaded to read our data and create our model were:



from sklearn.model_selection import train_test_split
from sklearn.dummy import DummyClassifier

# Install and update spaCy
!pip install -U spacy
!python -m spacy download fr

# Import necessary packages
import spacy
from spacy import displacy
from sklearn.feature_extraction.text import TfidfVectorizer

from sklearn.pipeline import Pipeline
import string
from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop
from spacy.lang.fr import French
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
